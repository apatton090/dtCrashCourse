{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Statistics\n",
    "## Chapter 1.4 - Discrete Random Variables\n",
    "Previously, events were defined using sets. Instead of explicitly defining sets (such as $A$ = {1,2,3,4}), we can use random variables and inequalities to defined them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition\n",
    "- Probability distribution\n",
    "    - A mathematical function that models/ describes the probability of a result occuring\n",
    "    - The probability that the random variable $X$ takes on the value $x$, $P(X=x)$\n",
    "        - The function is normally defined using an equation, but it could be defined using anything as 1 input corresponds to 1 output (such as a table or a histogram)\n",
    "\n",
    "## Notation\n",
    "- Events with random variable\n",
    "    - The event can be defined using random variables, a particular outcome, and inequalities\n",
    "    - e.g. $X=9, X\\le9, X=x, X\\le x$\n",
    "- Probability with random variable\n",
    "    - Same as probability of an event defined in chapter 1.1 expect the event is defined using a random variable instead of a set\n",
    "    - e.g. $P(X = 9)$, $P(X \\le 9)$, $P(X = x)$, $P(X \\le x)$\n",
    "    - $P(X = x)$ will sometimes be shorten to $p(x)$ or $p_X(x)$\n",
    "- Probability distribution\n",
    "    - $P(X = x)$,  $p(x)$, or $p_X(x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability Mass Function\n",
    "The probability distribution of a descrete random variable is also called a probability mass function (pmf). Typically, we only explicitly define the regions where the probability is $>0$. Everything that is not explicitly defined has a probability of $0$.\n",
    "\n",
    "Recall the axioms of probability:\n",
    "- $P(S) = 1$  \n",
    "- $P(A) \\ge 0$  \n",
    "- $P(S) = \\sum_{i=1}^n P(A_i)=1$, if $A_i$ are mutually exclusive for all $i$   \n",
    "\n",
    "Unsurprisingly, these also apply to the probability mass function. Lets define set $A$ to be events where $X = x$. Then using substitution, we get $P(X = x) \\le 1$. Lets define $A_i$ to be events events $X = x_i$. Clearly these events are mutually exclusive because an outcome cannot have 2 different results. Then using substitution again, we get $\\sum_{x_i} P(X = x_i) = P(S) = 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cumulative Distribution Function\n",
    "\n",
    "The cumulative distribution function (cdf) is the probability the random variable $X$ is less than or equal to a particular value $x$, and is typically denoted as $F(x)$. The cdf also just so happens to model the quantile of the distribution.\n",
    "- $F(x)=P(X \\le x)$\n",
    "\n",
    "We can also use the cdf to calculate the probability of $X$ being between the intervals $[x_1, x_2]$\n",
    "- $P(x_1 \\le X \\le x_2) = F(x_2) - F(x_1)$\n",
    "\n",
    "To calculate the cdf for a discrete random variable, you would calculate all of the pmfs from $-\\infty$ to $x$ and add them together\n",
    "- $F(x)=P(X \\le x) = \\sum _{y \\le x} p(y)$ \n",
    "\n",
    "Using the properties of a pmf, we can derive the properties of a cdf.\n",
    "- $\\lim_{x \\to -\\infty} F(x) = 0$\n",
    "    - No numerical result can have a value of $\\le -\\infty$. So if the set of events where $X \\le -\\infty$ must be the empty set, thus $P(X \\le \\infty) = 0$.\n",
    "- $\\lim_{x \\to \\infty} F(x) = 1$\n",
    "    - All numerical result must have a value of $\\le -\\infty$. So if the set of events where $X \\le \\infty$ must be the entire sample space, thus $P(X \\le \\infty) = 1$.\n",
    "- If $x_1 < x_2$, then $F(x_1) \\le F(x_2)$\n",
    "    - $F(x)$ is a nondecreasing function.\n",
    "    - This is because $p(x) \\ge 0$ for all values of $x$. It is impossible to decrease the cdf by adding more numbers $\\ge0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Value\n",
    "Expected value is the theoretically mean for a probability distribution. This is normally notated with a $E$ followed by the random variable in parenthese, e.g. $E(X)$, or the greek symbol mu, $\\mu$. The equation for expected value of a probability mass function is the following:\n",
    "- (1) $E(X) =\\mu= \\sum_x xP(X=x)$\n",
    "\n",
    "Lets see how this relates to the mean equation.\n",
    "- expected value equation\n",
    "    - $E(X) = \\sum_x xp(x)$  \n",
    "- rewrite $p(x)$ using the probability equation\n",
    "    - $= \\sum_x x\\frac{|X=x|}{|S|}$\n",
    "- move $|S|$ outside the summation because it is a constant\n",
    "    - $= \\frac{1}{|S|} \\sum_x x|X=x|$\n",
    "        - $|X=x|$ can be intrepted as the number of times $X=x$ occurred\n",
    "        - $\\sum_x x|X=x|$ can be intrepted as grouping the results together and finding the sum of those first. Then summing everything together after.\n",
    "        - $\\frac{1}{|S|}$ can be intrepted as dividing everything by the total\n",
    "    - The overall intreptation is the same as the mean equation, sum up all of the results and dividing it by the total number of events. However, the expected value equation sum the same results first before summing everything together.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Properties of Expected Value\n",
    "Expected value of a probability distribution will always yield the same result. This means that expected value has no randomness (behaving like a random variable, potentially having a different result) therefore it is a constant. This differs from a function of random variables, such as sample mean, $\\bar y$. This is because using a different set of random variables may yield a different value.\n",
    "\n",
    "### Equations\n",
    "- (2) $E(g(X)) = \\sum_x g(x)p(x)$\n",
    "    - You would think that $E(g(X)) = \\sum_x g(x)p(g(x))$\n",
    "    - $p(g(x)) = p(x)$\n",
    "        - This is because $|x|$ and the $|g(x)|$ is the same, but with different values\n",
    "- (3) $E(c) = c$\n",
    "    - $c$ is a constant\n",
    "- (4) $E(cX) = cE(X)$\n",
    "- (5) $E(X + Y) = E(X) + E(Y)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance\n",
    "The theoretical variance is normally notated as $Var$ or $V$ followed by the random variance in parenthese, e.g. $Var(X)$ or $V(X)$. The equation for the theoretical variance is defined as the following:\n",
    "- (6) $Var(X) = E[(X - \\mu)^2]$ \n",
    "    - Using equation 2, we can that $Var(X)= \\sum_x (x-\\mu)^2p(x)$\n",
    "\n",
    "Since $\\mu$ can be interpreted as the \"mean\" of the distribution. The variance equation can be interpreted as the average of the squared difference between the result and the mean. Since the difference is squared, the following must be true:\n",
    "- $Var(X) \\ge 0$\n",
    "\n",
    "Notice that the sample variance equation is not the average of the squared difference the result and the mean. Instead of dividing by $n$, it divides by $n-1$.  \n",
    "- $\\frac{1}{n-1} \\sum_{i=1}^n(y_i-\\bar{y}^2)$\n",
    "\n",
    "This is because of several reasons:\n",
    "- Using $\\frac{1}{n}$ yields a biased estimator, covered in a later chapter$\n",
    "- Has $n-1$ degrees of freedom\n",
    "    - Degrees of freedom refers to the number of values that are free to vary\n",
    "    - The equation uses $\\bar y$, which uses the data to calculate. This means $\\bar y$ holds information about the data. So we have to factor that in when calculating variance.\n",
    "        - $\\bar y$ has the following property: $\\sum_{i=1}^n (y_i - \\bar y) = 0$\n",
    "        - This means that n - 1 number of data can be anything, but the nth data must be a value that satisfy the constaint above.\n",
    "\n",
    "We can also rearrange the equation into:\n",
    "- (7) $Var(X) = E(X^2) - \\mu^2 = \\sum_x (x)^2p(x) - \\mu^2$\n",
    "    - $Var(X) = E[(X - \\mu)^2] = E[X^2 - 2X\\mu + \\mu^2] = E(X^2) - E(2X\\mu) + E(\\mu^2)$\n",
    "        - Note: $\\mu$ is a constant\n",
    "    - $ = E(X^2) - 2\\mu E(X) + E(\\mu^2) = E(X^2) - 2\\mu^2 + E(\\mu^2) = E(X^2) - \\mu^2$\n",
    "- This is a useful property of variance, I don't think this has great interpretation value.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Properties of Variance\n",
    "Similar to expected value, variance is a constant while sample variance is a random variable.\n",
    "\n",
    "### Equations\n",
    "- (8) $Var(c) = 0$\n",
    "    - $c$ is a constant\n",
    "- (9) $Var(X + c) = Var(X)$\n",
    "    - $Var(X+c) = E[(X+c - E(X+c))^2] = E[(X+c - E(X) - c)^2] = E[(X - E(X))^2] = Var(X)$\n",
    "    - This can be interpreted as the spread of the data staying the same\n",
    "- (10) $Var(aX) = a^2Var(X)$\n",
    "    - $Var(aX) = E[(aX - a\\mu)^2] = E[a^2(X - \\mu)^2] = a^2 E[(X - \\mu)^2] = a^2Var(X)$\n",
    "- (11) $Var(X + Y) = Var(X) + Var(Y)$, if $X$ and $Y$ are independent\n",
    "- (12) $Var(aX + bY) = a^2Var(X) + b^2Var(Y) + abCov(X, Y)$\n",
    "    - $Cov$ will be discussed in a later chapter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equations\n",
    "Expected Value  \n",
    "1) $E(X) =\\mu= \\sum_x xP(X=x)$  \n",
    "2) $E(g(X)) = \\sum_x g(x)p(x)$  \n",
    "3) $E(c) = c$  \n",
    "4) $E(cX) = cE(X)$  \n",
    "5) $E(X + Y) = E(X) + E(Y)$  \n",
    "\n",
    "Variance  \n",
    "6) $Var(X) = E[(X - \\mu)^2]$   \n",
    "7) $Var(X) = E(X^2) - \\mu^2 = \\sum_x (x)^2p(x) - \\mu^2$  \n",
    "8) $Var(c) = 0$  \n",
    "9) $Var(X + c) = Var(X)$  \n",
    "10) $Var(aX) = a^2Var(X)$  \n",
    "11) $Var(X + Y) = Var(X) + Var(Y)$, if $X$ and $Y$ are independent  \n",
    "12) $Var(aX + bY) = a^2Var(X) + b^2Var(Y) + abCov(X, Y)$  \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}