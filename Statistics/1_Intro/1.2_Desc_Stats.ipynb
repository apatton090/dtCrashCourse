{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction - Descriptive Statistics\n",
    "\n",
    "Data by itself is useless. We need to transform the data so it can be analyzed and understood by people. Graphical transforms are great way to visualizing and understanding the data. 2 simple and commonly used graphical representation are a histograms and scatter plots. Graphs are great starting point for data analysis, but we cannot \"do math\" on graphs. Descriptive statistics are numberic values that quantify/ describes the features of the graphs so we can do rigorous, mathematical data analysis. It is important to note the equations for these values calculated from a sample. The theoretical definitions/ equations will be covered later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions\n",
    "- Population\n",
    "    - The group of people, items, or events that is related to the question of interest\n",
    "- Sample\n",
    "    - A subset of the population that we have data for\n",
    "- Statistic\n",
    "    - A value computed from the data\n",
    "- Outlier\n",
    "    - A data value that is significantly different from the rest of the dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate\n",
    "\n",
    "Uni- means one, and variate means random variable. So, univariate means one random variable. This means all of the results from the random trail are of the same characteristic/ attribute. Histograms are commonly used to visualize univariate data. Descriptive statistics for univariate data are in 2 general categories: measure of central tendency and measure of variability. It is important to note that these summary statistic are best used on data that are unimodal or having 1 hump on the histogram. For data that are multimodal, these can be used with caution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure of Central Tendency\n",
    "Central tendency is the typical value of the data. The 3 most commonly used ones are: (arithmetic) mean, median, and mode.\n",
    "\n",
    "### Mean  \n",
    "The mean is defined as the sum of the data divided by the number of data.\n",
    "- $y_{mean} = \\bar{y} = \\frac{1}{n} \\sum_{i=1}^n y_i$\n",
    "\n",
    "### Median \n",
    "The median is defined as the value where 50% of the data is greater than or equal to it.\n",
    "- $y_{median} = $ middle number of the ordered values  \n",
    "\n",
    "If the number of data is odd, then the middle number is the median. If the number of data is even, then the average of the 2 middle number is the median.\n",
    "\n",
    "### Mode\n",
    "The mode is defined as the value with the highest frequency.\n",
    "- $y_{mode} = $ most common number\n",
    "\n",
    "There may be more than 1 mode in the data.\n",
    "\n",
    "### Comparison\n",
    "When it comes to outliers, median and mode are more robust to outliers. This is because a large outlier can significantly change the mean, but it will hardly affect the median or the mode. However, mean has better mathematical properties, such as being differentiable.  \n",
    "\n",
    "Which one is the best depends on the situation. Typically mean is preferred because outliers can be removed from the data set and it has superior mathematical properties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure of Variability/ Dispersion\n",
    "\n",
    "This is measure of how spread appart is the data/ histogram. \n",
    "\n",
    "### Variance and Standard Deviation \n",
    "Variance is defined as the following:\n",
    "- variance = $\\sigma^2 = \\frac{1}{n-1} \\sum_{i=1}^n(y_i-\\bar{y}^2)$\n",
    "\n",
    "Standard deviation is the square root of the variance\n",
    "- standard deviation = $\\sigma = \\sqrt{\\frac{1}{n-1} \\sum_{i=1}^n(y_i-\\bar{y}^2)}$\n",
    "\n",
    "### Range\n",
    "Range is defined to be the difference between the maximum and minimun value of the dataset.\n",
    "- range = $max(y_1, y_2, ..., y_n) - min(y_1, y_2, ..., y_n)$\n",
    "\n",
    "### Interquartile range\n",
    "The nth percentile is the number that is greater than n% of the dataset.\n",
    "\n",
    "A quartile splits the dataset into 4 equal segments. The 1st quartile (Q1) is defined to contain all of values that are between the smallest value of the dataset and the 25th percentile. The 2nd quartile (Q2) is defined to contain all of the values that are between the 25th and 50th percentile. The 3rd quartile (Q3) is defined to contain all of the values between the 50% and 75% percentile. The 4th quartile (Q4) is defined to contain all of the values from the 75% percentile to the larges value of the dataset.\n",
    "\n",
    "The Interquartile range (IQR) is defined to be the difference between the 3rd and 1st quartile.\n",
    "- IQR = $Q3 - Q1$\n",
    "\n",
    "### Comparison\n",
    "IQR is the most robust to outliers, followed by variance/ standard deviation, and finally range. However, variance  has the best mathematical properties since it is differentiable. \n",
    "\n",
    "Typically, variance is the preferred due to the fact it is differentiable. After doing math using the variance, it is typically converted into standard deviation because it is easier to intrept.\n",
    "\n",
    "### Shape of Histogram\n",
    "There are statistic that describe the shape of the histogram: skewness and kurtosis. It can be though of as discribing how uneven is the spread of the data. We will not cover how to calculated skewness and kurtosis and kurtosis will not be covered at all.\n",
    "\n",
    "Skewness refers to if the histogram has long left tail, right tail, or symmetric. If it has a long left tail, then is it said to be skewed-left or negative skew. If it has a long right tail, then it is said to be skewed-right or positive skew. If it has no tail, then it is said to be symmetric or 0 skew. When it is skewed-left, then $y_{mode}> y_{median} > y_{mean}$. When it is skewed-right, then $y_{mode} < y_{median} < y_{mean}$. When it is skewed-right, then $y_{mode} \\approx y_{median} \\approx y_{mean}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bivariate\n",
    "Bi- means 2, and variate means random variable. So, bivariate means 2 random variable. This means all of the results from the random trail are of the same 2 characteristic/ attribute. Scatter plots are commonly used to visualize bivariate data.\n",
    "\n",
    "You can have even more variables (multivariate); however, there are no easy way to visualize the entire data in a single graph. So, typically you would create a scatter plot for each pair of variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covariance and Correlation\n",
    "They are both measure how linearly dependant are the 2 variables. In other words, this measures how tight of a line does the scatter plot make. The sample covariance is defined as the following:\n",
    "- covariance = $Cov(X, Y) = \\frac{1}{n-1} \\sum_{i=1}^n [(x_i-\\bar{x})(y_i-\\bar{y})]$\n",
    "\n",
    "Correlation is the covariance divided by the standard deviation of the 2 variables.\n",
    "- correlation = $Cor(X,Y) = \\frac{Cov(X, Y)}{\\sigma_X \\sigma_Y}$\n",
    "\n",
    "This has the effect of normalizing the covariance to be between -1 and 1. A positive sign for the correlation corresponds the 2 variables having a positive relationship, and a negative sign corresponds to a negative relationship. The closer the magnitude of the correlation is to 1, the stronger linear dependance is. It is important to note that no part of covariance or correlation indicate the slope of the line.\n",
    "\n",
    "Typically, covariance is used for calculations because it is differentiable, then converted to correlation for interepation. Correlation is not differentiable because standard deviation is not differentiable.\n",
    "\n",
    "It is important to note that covariance and correlation only measures the strength of the linear relationship, not overall relationship. If the 2 variables has a strong nonlinear relationship (like a quadratic relationship), the covariance and correlation will still give a value. This value is not a good measure of nonlinear relationship and should be used with caution."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}